{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decode data from all images in a folder and save data as .txt file with proper size (1 px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def remove_65(data):\n",
    "    data = np.array(data)  # Ensure input is a NumPy array\n",
    "    duplicate_indices = []\n",
    "\n",
    "    # Find consecutive duplicates in the slice\n",
    "    if len(data) == 129: \n",
    "        # Find the smallest number and its index in the range 0 to 64\n",
    "        min_index_0_128 = min(range(0, 128), key=lambda i: data[i])\n",
    "        duplicate_indices.append(min_index_0_128) \n",
    "\n",
    "    if len(data) == 130:\n",
    "        # Find the smallest number and its index in the range 0 to 64\n",
    "        min_index_0_64 = min(range(0, 65), key=lambda i: data[i])\n",
    "        duplicate_indices.append(min_index_0_64)\n",
    "        # Find the smallest number and its index in the range 65 to 129\n",
    "        min_index_65_129 = min(range(65, 130), key=lambda i: data[i])\n",
    "        duplicate_indices.append(min_index_65_129)\n",
    "        # Remove the smallest elements from both ranges\n",
    "        \n",
    "    if len(data) == 131:\n",
    "        # Find the smallest number and its index in the range 0 to 64\n",
    "        min_index_0_64 = min(range(0, 64), key=lambda i: data[i])\n",
    "        duplicate_indices.append(min_index_0_64)\n",
    "        # Find the smallest number and its index in the range 65 to 129\n",
    "        min_index_65_129 = min(range(66, 131), key=lambda i: data[i])\n",
    "        duplicate_indices.append(min_index_65_129)\n",
    "        # Remove 66th value\n",
    "        duplicate_indices.append(65)\n",
    "    \n",
    "    # Create a mask to filter out the duplicates\n",
    "    mask = np.ones(len(data), dtype=bool)\n",
    "    mask[duplicate_indices] = False\n",
    "    updated_data = data[mask]\n",
    "\n",
    "    return updated_data, duplicate_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "for k in range(451, 501):\n",
    "    # Define input and output directories\n",
    "    input_directory = fr'F:\\My File\\OCC_Nov_11\\Datasets_L8_8_subcarrier\\6_test_rx_image\\m{k}'  # Folder containing the tiff images\n",
    "    output_directory= fr'F:\\My File\\OCC_Nov_11\\Datasets_L8_8_subcarrier\\7_test_rx_decoded_data\\m{k}'  # Folder to save the decoded data\n",
    "\n",
    "    # Define the batch size\n",
    "    batch_size = 128  # Adjust the batch size as per your needs\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # Get all TIFF files in the input directory\n",
    "    tiff_files = [f for f in os.listdir(input_directory) if f.endswith('.tiff')]\n",
    "\n",
    "    # Define the threshold\n",
    "    threshold = 15.0  # Define threshold for batch separation\n",
    "\n",
    "    # Loop over all TIFF files in the input directory\n",
    "    for tiff_file in tiff_files:\n",
    "        # Load each TIFF image\n",
    "        image_path = os.path.join(input_directory, tiff_file)\n",
    "        image = Image.open(image_path)\n",
    "        image_data = np.array(image).astype(float)\n",
    "\n",
    "        # Extract specific column range (e.g., columns 850 to 1000)\n",
    "        columns_range_data = image_data[:, 800:1100]\n",
    "        column_avg = np.mean(columns_range_data, axis=1)\n",
    "\n",
    "        # Flatten the array of column-averaged values\n",
    "        flat_column_avg = column_avg.flatten()\n",
    "        \n",
    "        # Initialize variables for batch creation\n",
    "        batches_column_avg = []\n",
    "        current_batch_avg = []\n",
    "        inside_batch_avg = False\n",
    "\n",
    "        # Create batches based on pixel intensity\n",
    "        for avg_pixel in flat_column_avg:\n",
    "            if avg_pixel <= threshold:\n",
    "                # If inside a batch and value <= threshold, finalize the current batch\n",
    "                if inside_batch_avg and current_batch_avg:\n",
    "                    batches_column_avg.append(current_batch_avg)\n",
    "                    current_batch_avg = []\n",
    "                inside_batch_avg = True  # Start a new batch when <= threshold encountered\n",
    "            else:\n",
    "                if inside_batch_avg:\n",
    "                    current_batch_avg.append(avg_pixel)\n",
    "\n",
    "        # Append the last batch if not empty\n",
    "        if current_batch_avg:\n",
    "            batches_column_avg.append(current_batch_avg)\n",
    "\n",
    "        # Process each batch: Average every two pixels while ensuring the last pixel is removed if the averaged batch size isn't divisible by 16\n",
    "        averaged_batches = []\n",
    "\n",
    "        # Process each batch and average every two pixels, excluding first and last batch\n",
    "        for i, batch in enumerate(batches_column_avg[0:-1], start=0):  # Exclude first and last batch\n",
    "            #print(f\"\\nProcessing file: {tiff_file}, Batch {i}: Original Data{np.array(batch).shape}\")\n",
    "            #print(np.array(batch))  # Print the original batch content\n",
    "            updated_data, removed_indices = remove_65(batch)\n",
    "            # Averaging every two pixels\n",
    "            averaged_batch = []\n",
    "            for j in range(0, len(updated_data), 1):\n",
    "                # Ensure there is a pair to average\n",
    "                avg_of_two = (updated_data[j])\n",
    "                averaged_batch.append(avg_of_two)\n",
    "\n",
    "            # Remove the last pixel if the averaged batch size is not a multiple of 16\n",
    "            if len(averaged_batch)>128:\n",
    "                if len(averaged_batch) % 8 != 0: \n",
    "                    averaged_batch = averaged_batch[:-(len(averaged_batch) % 8)]\n",
    "\n",
    "            # Round the averaged batch to 4 decimal places\n",
    "            averaged_batch = np.round(averaged_batch, 4)\n",
    "\n",
    "            # Print the averaged batch\n",
    "            #print(f\"Batch {i}: Averaged every two pixels\")\n",
    "            #print(np.array(averaged_batch))  # Print the averaged values\n",
    "            #print(f\"Shape of Averaged Batch {i}: {np.array(averaged_batch).shape}\")\n",
    "\n",
    "            # Check if the current batch has the required length\n",
    "            if len(averaged_batch) == batch_size:\n",
    "                # Convert list to comma-separated string\n",
    "                formatted_list = ', '.join(map(str, averaged_batch))\n",
    "\n",
    "                # Save the batch to a text file (e.g., m1.txt, m2.txt, etc.)\n",
    "                output_file_name = os.path.join(output_directory, f\"{os.path.splitext(tiff_file)[0]}m{i}.txt\")\n",
    "                with open(output_file_name, 'w') as file:\n",
    "                    file.write(f\"{formatted_list}\")\n",
    "\n",
    "                # Print confirmation\n",
    "                #print(f\"Batch {i} from file {tiff_file} saved to {output_file_name} with length {len(averaged_batch)}\")\n",
    "            else:\n",
    "                print(f\"Batch {i} skipped, length {len(averaged_batch)} (expected length: {batch_size})\")\n",
    "\n",
    "print(\"Processing complete for all TIFF files.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decode data from all images in a folder and save data as .txt file with proper size (2 px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "for k in range(426, 446):\n",
    "    # Define input and output directories\n",
    "    input_directory = fr'F:\\My File\\OCC_Nov_11\\Dataset_16subcarrier\\5_test_rx_image\\m{k}'  # Folder containing the tiff images\n",
    "    output_directory=fr'F:\\My File\\OCC_Nov_11\\Dataset_16subcarrier\\6_test_rx_decoded_data\\m{k}'  # Folder to save the decoded data\n",
    "\n",
    "    # Define the batch size\n",
    "    batch_size = 256  # Adjust the batch size as per your needs\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # Get all TIFF files in the input directory\n",
    "    tiff_files = [f for f in os.listdir(input_directory) if f.endswith('.tiff')]\n",
    "\n",
    "    # Define the threshold\n",
    "    threshold = 15.0  # Define threshold for batch separation\n",
    "\n",
    "\n",
    "    # Loop over all TIFF files in the input directory\n",
    "    for tiff_file in tiff_files:\n",
    "        # Load each TIFF image\n",
    "        image_path = os.path.join(input_directory, tiff_file)\n",
    "        image = Image.open(image_path)\n",
    "        image_data = np.array(image).astype(float)\n",
    "\n",
    "        # Extract specific column range (e.g., columns 850 to 1000)\n",
    "        columns_range_data = image_data[:, 800:1100]\n",
    "        column_avg = np.mean(columns_range_data, axis=1)\n",
    "\n",
    "        # Flatten the array of column-averaged values\n",
    "        flat_column_avg = column_avg.flatten()\n",
    "        updated_data, removed_indices = remove_consecutive_duplicates(flat_column_avg)\n",
    "        # print(\"Updated Data:\", updated_data)\n",
    "\n",
    "        # Initialize variables for batch creation\n",
    "        batches_column_avg = []\n",
    "        current_batch_avg = []\n",
    "        inside_batch_avg = False\n",
    "\n",
    "        # Create batches based on pixel intensity\n",
    "        for avg_pixel in updated_data:\n",
    "            if avg_pixel <= threshold:\n",
    "                # If inside a batch and value <= threshold, finalize the current batch\n",
    "                if inside_batch_avg and current_batch_avg:\n",
    "                    batches_column_avg.append(current_batch_avg)\n",
    "                    current_batch_avg = []\n",
    "                inside_batch_avg = True  # Start a new batch when <= threshold encountered\n",
    "            else:\n",
    "                if inside_batch_avg:\n",
    "                    current_batch_avg.append(avg_pixel)\n",
    "\n",
    "        # Append the last batch if not empty\n",
    "        if current_batch_avg:\n",
    "            batches_column_avg.append(current_batch_avg)\n",
    "\n",
    "        # Process each batch: Average every two pixels while ensuring the last pixel is removed if the averaged batch size isn't divisible by 16\n",
    "        averaged_batches = []\n",
    "\n",
    "        # Process each batch and average every two pixels, excluding first and last batch\n",
    "        for i, batch in enumerate(batches_column_avg[1:-1], start=1):  # Exclude first and last batch\n",
    "            #print(f\"\\nProcessing file: {tiff_file}, Batch {i}: Original Data{np.array(batch).shape}\")\n",
    "            #print(np.array(batch))  # Print the original batch content\n",
    "\n",
    "            # Averaging every two pixels\n",
    "            averaged_batch = []\n",
    "            for j in range(0, len(batch), 1):\n",
    "                # Ensure there is a pair to average\n",
    "                avg_of_two = (batch[j])\n",
    "                averaged_batch.append(avg_of_two)\n",
    "\n",
    "            # Remove the last pixel if the averaged batch size is not a multiple of 16\n",
    "            if len(averaged_batch) % 16 != 0:\n",
    "                averaged_batch = []\n",
    "                for j in range(1, len(batch), 1):\n",
    "                    # Ensure there is a pair to average\n",
    "                    avg_of_two = (batch[j])\n",
    "                    averaged_batch.append(avg_of_two)\n",
    "                averaged_batch = averaged_batch[:-(len(averaged_batch) % 16)]\n",
    "\n",
    "            # Round the averaged batch to 4 decimal places\n",
    "            averaged_batch = np.round(averaged_batch, 4)\n",
    "\n",
    "            # Print the averaged batch\n",
    "            #print(f\"Batch {i}: Averaged every two pixels\")\n",
    "            #print(np.array(averaged_batch))  # Print the averaged values\n",
    "            #print(f\"Shape of Averaged Batch {i}: {np.array(averaged_batch).shape}\")\n",
    "\n",
    "            # Check if the current batch has the required length\n",
    "            if len(averaged_batch) == batch_size:\n",
    "                # Convert list to comma-separated string\n",
    "                formatted_list = ', '.join(map(str, averaged_batch))\n",
    "\n",
    "                # Save the batch to a text file (e.g., m1.txt, m2.txt, etc.)\n",
    "                output_file_name = os.path.join(output_directory, f\"m{os.path.splitext(tiff_file)[0]}{i}.txt\")\n",
    "                with open(output_file_name, 'w') as file:\n",
    "                    file.write(f\"{formatted_list}\")\n",
    "\n",
    "                # Print confirmation\n",
    "                #print(f\"Batch {i} from file {tiff_file} saved to {output_file_name} with length {len(averaged_batch)}\")\n",
    "            else:\n",
    "                print(f\"Batch {i} skipped, length {len(averaged_batch)} (expected length: {batch_size})\")\n",
    "\n",
    "print(\"Processing complete for all TIFF files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Define input and output directories\n",
    "input_directory = r'E:\\Minhaz\\iot\\OCC_sep_5\\new_dataset_16_10\\rx_image_dataset_66khz\\m104'  # Folder containing the tiff images\n",
    "output_directory =r'E:\\Minhaz\\iot\\OCC_sep_5\\new_dataset_equalizer_10_24\\rx_decoded_data\\m104'  # Folder to save the decoded data\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 80  # Adjust the batch size as per your needs\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Get all TIFF files in the input directory\n",
    "tiff_files = [f for f in os.listdir(input_directory) if f.endswith('.tiff')]\n",
    "\n",
    "# Define the threshold\n",
    "threshold = 30.0  # Define threshold for batch separation\n",
    "\n",
    "\n",
    "# Loop over all TIFF files in the input directory\n",
    "for tiff_file in tiff_files:\n",
    "    # Load each TIFF image\n",
    "    image_path = os.path.join(input_directory, tiff_file)\n",
    "    image = Image.open(image_path)\n",
    "    image_data = np.array(image).astype(float)\n",
    "\n",
    "    # Extract specific column range (e.g., columns 850 to 1000)\n",
    "    columns_range_data = image_data[:, 850:1000]\n",
    "    column_avg = np.mean(columns_range_data, axis=1)\n",
    "\n",
    "    # Flatten the array of column-averaged values\n",
    "    flat_column_avg = column_avg.flatten()\n",
    "\n",
    "    # Initialize variables for batch creation\n",
    "    batches_column_avg = []\n",
    "    current_batch_avg = []\n",
    "    inside_batch_avg = False\n",
    "\n",
    "    # Create batches based on pixel intensity\n",
    "    for avg_pixel in flat_column_avg:\n",
    "        if avg_pixel <= threshold:\n",
    "            # If inside a batch and value <= threshold, finalize the current batch\n",
    "            if inside_batch_avg and current_batch_avg:\n",
    "                batches_column_avg.append(current_batch_avg)\n",
    "                current_batch_avg = []\n",
    "            inside_batch_avg = True  # Start a new batch when <= threshold encountered\n",
    "        else:\n",
    "            if inside_batch_avg:\n",
    "                current_batch_avg.append(avg_pixel)\n",
    "\n",
    "    # Append the last batch if not empty\n",
    "    if current_batch_avg:\n",
    "        batches_column_avg.append(current_batch_avg)\n",
    "\n",
    "    # Process each batch: Average every two pixels while ensuring the last pixel is removed if the averaged batch size isn't divisible by 16\n",
    "    averaged_batches = []\n",
    "\n",
    "    # Process each batch and average every two pixels, excluding first and last batch\n",
    "    for i, batch in enumerate(batches_column_avg[1:-1], start=1):  # Exclude first and last batch\n",
    "        print(f\"\\nProcessing file: {tiff_file}, Batch {i}: Original Data{np.array(batch).shape}\")\n",
    "        print(np.array(batch))  # Print the original batch content\n",
    "\n",
    "        # Averaging every two pixels\n",
    "        averaged_batch = []\n",
    "        for j in range(0, len(batch), 2):\n",
    "            # Ensure there is a pair to average\n",
    "            if j + 1 < len(batch):\n",
    "                avg_of_two = (batch[j] + batch[j + 1]) / 2\n",
    "                averaged_batch.append(avg_of_two)\n",
    "\n",
    "        # Remove the last pixel if the averaged batch size is not a multiple of 16\n",
    "        if len(averaged_batch) % 16 != 0:\n",
    "            averaged_batch = averaged_batch[:-(len(averaged_batch) % 16)]\n",
    "\n",
    "        # Round the averaged batch to 4 decimal places\n",
    "        averaged_batch = np.round(averaged_batch, 4)\n",
    "\n",
    "        # Print the averaged batch\n",
    "        print(f\"Batch {i}: Averaged every two pixels\")\n",
    "        print(np.array(averaged_batch))  # Print the averaged values\n",
    "        print(f\"Shape of Averaged Batch {i}: {np.array(averaged_batch).shape}\")\n",
    "\n",
    "        # Check if the current batch has the required length\n",
    "        if len(averaged_batch) == batch_size:\n",
    "            # Convert list to comma-separated string\n",
    "            formatted_list = ', '.join(map(str, averaged_batch))\n",
    "\n",
    "            # Save the batch to a text file (e.g., m1.txt, m2.txt, etc.)\n",
    "            output_file_name = os.path.join(output_directory, f\"{os.path.splitext(tiff_file)[0]}m{i}.txt\")\n",
    "            with open(output_file_name, 'w') as file:\n",
    "                file.write(f\"{formatted_list}\")\n",
    "\n",
    "            # Print confirmation\n",
    "            print(f\"Batch {i} from file {tiff_file} saved to {output_file_name} with length {len(averaged_batch)}\")\n",
    "        else:\n",
    "            print(f\"Batch {i} skipped, length {len(averaged_batch)} (expected length: {batch_size})\")\n",
    "\n",
    "print(\"Processing complete for all TIFF files.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decode data from images and save data as .txt file with proper size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Load the TIFF image\n",
    "image_path = r'E:\\Minhaz\\iot\\OCC_sep_5\\new_dataset_16_10\\rx_image_dataset_66khz\\m39\\1.tiff'  # Update with the correct file path / change file name\n",
    "# Define output directory to save the files\n",
    "output_directory = r'E:\\Minhaz\\iot\\OCC_sep_5\\new_dataset_16_10\\Rx_decoded_data\\m39' # change the folder name\n",
    "\n",
    "image = Image.open(image_path)\n",
    "image_data = np.array(image).astype(float)\n",
    "\n",
    "# Extract specific column range (951 to 1000)\n",
    "columns_range_data = image_data[:, 850:1050]\n",
    "column_avg = np.mean(columns_range_data, axis=1)\n",
    "\n",
    "# Flatten the array of column-averaged values\n",
    "flat_column_avg = column_avg.flatten()\n",
    "\n",
    "# Initialize variables for batch creation\n",
    "batches_column_avg = []\n",
    "current_batch_avg = []\n",
    "threshold = 20.0  # Define threshold for batch separation\n",
    "inside_batch_avg = False\n",
    "\n",
    "# Create batches based on pixel intensity\n",
    "for avg_pixel in flat_column_avg:\n",
    "    if avg_pixel <= threshold:\n",
    "        # If inside a batch and value <= threshold, finalize the current batch\n",
    "        if inside_batch_avg and current_batch_avg:\n",
    "            batches_column_avg.append(current_batch_avg)\n",
    "            current_batch_avg = []\n",
    "        inside_batch_avg = True  # Start a new batch when <= threshold encountered\n",
    "    else:\n",
    "        if inside_batch_avg:\n",
    "            current_batch_avg.append(avg_pixel)\n",
    "\n",
    "# Append the last batch if not empty\n",
    "if current_batch_avg:\n",
    "    batches_column_avg.append(current_batch_avg)\n",
    "\n",
    "# Process each batch: Average every two pixels while ensuring the last pixel is removed if the averaged batch size isn't divisible by 16\n",
    "averaged_batches = []\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Process each batch and average every two pixels, excluding first and last batch\n",
    "for i, batch in enumerate(batches_column_avg[1:-1], start=1):  # Exclude first and last batch\n",
    "    print(f\"\\nBatch {i}: Original Data{np.array(batch).shape}\")\n",
    "    print(np.array(batch))  # Print the original batch content\n",
    "\n",
    "    # Averaging every two pixels\n",
    "    averaged_batch = []\n",
    "    for j in range(0, len(batch), 2):\n",
    "        # Ensure there is a pair to average\n",
    "        if j + 1 < len(batch):\n",
    "            avg_of_two = (batch[j] + batch[j + 1]) / 2\n",
    "            averaged_batch.append(avg_of_two)\n",
    "\n",
    "    # Remove the last pixel if the averaged batch size is not a multiple of 16\n",
    "    if len(averaged_batch) % 16 != 0:\n",
    "        averaged_batch = averaged_batch[:-(len(averaged_batch) % 16)]\n",
    "\n",
    "    # Round the averaged batch to 4 decimal places\n",
    "    averaged_batch = np.round(averaged_batch, 4)\n",
    "\n",
    "    # Print the averaged batch\n",
    "    print(f\"Batch {i}: Averaged every two pixels\")\n",
    "    print(np.array(averaged_batch))  # Print the averaged values\n",
    "    print(f\"Shape of Averaged Batch {i}: {np.array(averaged_batch).shape}\")\n",
    "\n",
    "    # Convert the list to a format with commas\n",
    "    formatted_list = ', '.join(map(str, averaged_batch))\n",
    "\n",
    "    # Check if the current batch has the maximum length\n",
    "    if len(averaged_batch) == 160:  # change batch size\n",
    "        # Convert list to comma-separated string\n",
    "        formatted_list = ', '.join(map(str, averaged_batch))\n",
    "\n",
    "        # Save the batch to a text file named m1.txt, m2.txt, etc.\n",
    "        file_name = os.path.join(output_directory, f\"mi1{i}.txt\")\n",
    "        with open(file_name, 'w') as file:\n",
    "            file.write(f\"{formatted_list}\")\n",
    "        \n",
    "        # Print confirmation\n",
    "        print(f\"Batch {i} saved to {file_name} with length {len(averaged_batch)}\")\n",
    "    else:\n",
    "        print(f\"Batch {i} skipped, length {len(averaged_batch)} (max length is 128)\")\n",
    "\n",
    "# Optionally, you could visualize the batches or perform further analysis\n",
    "# This would depend on how you wish to analyze or present the data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rename files in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Define the directory path\n",
    "# directory = r\"E:\\Minhaz\\iot\\OCC_sep_5\\new_dataset_16_10\\rx_image_dataset_66khz\\m10\"\n",
    "\n",
    "# # List all files in the directory\n",
    "# files = sorted(os.listdir(directory))\n",
    "\n",
    "# # Loop over the files and rename them\n",
    "# for index, filename in enumerate(files):\n",
    "#     if filename.endswith(\".tiff\"):  # Ensure the file is a tiff image\n",
    "#         new_name = f\"{index + 1}.tiff\"  # New file name\n",
    "#         old_file = os.path.join(directory, filename)\n",
    "#         new_file = os.path.join(directory, new_name)\n",
    "#         os.rename(old_file, new_file)\n",
    "#         print(f\"Renamed {filename} to {new_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rename files in the folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Base directory path\n",
    "base_directory = fr\"F:\\My File\\OCC_Nov_11\\Datasets_L8_8_subcarrier\\3_rx_image\"\n",
    "\n",
    "# Loop through folders m1 to m425\n",
    "for folder_number in range(1, 506):\n",
    "    directory = os.path.join(base_directory, f\"m{folder_number}\")\n",
    "    \n",
    "    # List all files in the directory\n",
    "    files = sorted(os.listdir(directory))\n",
    "    \n",
    "    # Loop over the files and rename them\n",
    "    for index, filename in enumerate(files):\n",
    "        if filename.endswith(\".tiff\"):  # Ensure the file is a tiff image\n",
    "            new_name = f\"{index + 1}.tiff\"  # New file name\n",
    "            old_file = os.path.join(directory, filename)\n",
    "            new_file = os.path.join(directory, new_name)\n",
    "            os.rename(old_file, new_file)\n",
    "            print(f\"Renamed {filename} in folder m{folder_number} to {new_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff03dcfaa4ea4c7dbcc7a6acd2b5152b484988a1b13020911f06ea29377d1915"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
